{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ9ctNXCUR7B",
    "outputId": "a67851d6-1434-48ff-b13d-17a3e3b9838d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uv3dQ_vNKhbd",
    "outputId": "b55aac27-4d16-483c-cc62-ca51050b3364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyenchant in /usr/local/lib/python3.7/dist-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyenchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PguALG6LRHB",
    "outputId": "e125240d-9e07-408d-86ea-8a1f639366cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet, stopwords, words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "#import enchant\n",
    "#checker = pyenchant.Dict(\"en_US\")\n",
    "from itertools import combinations\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IehL2X-dLdQd",
    "outputId": "889fbfb3-4ba8-4ae0-f648-82849e425a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('glove-twitter-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "id": "eGlyMMslRU1u"
   },
   "outputs": [],
   "source": [
    "class SpyMasterAI:\n",
    "  def __init__(self, model = None, red_words = None, blue_words = None, \n",
    "               assa_word = None, czn_words = None):\n",
    "    if(model == None or red_words == None or \n",
    "       blue_words == None or assa_word == None or czn_words == None):\n",
    "      raise Exception(\"Please enter the all parameters\")\n",
    "    self.red_words = red_words\n",
    "    self.blue_words = blue_words\n",
    "    self.assa_word = assa_word\n",
    "    self.czn_words = czn_words\n",
    "    self.ally_label = 'red'\n",
    "    self.ally_team = None\n",
    "    self.enemy_team = None\n",
    "    self.model = model\n",
    "    self.arr_similar = None\n",
    "    self.choose_side(self.ally_label)\n",
    "    self.max_comb = 4\n",
    "\n",
    "  \n",
    "  def get_closer_word(self,ally_team, enemy_team):\n",
    "    self.arr_similar = self.model.most_similar(ally_team,enemy_team)\n",
    "    return self.clean_arr()\n",
    "\n",
    "  def choose_side(self,ally_label):\n",
    "    if(ally_label == 'red'):\n",
    "      self.ally_team = self.red_words \n",
    "      self.enemy_team = self.blue_words\n",
    "    else:\n",
    "      self.ally_team = self.blue_words \n",
    "      self.enemy_team = self.red_words\n",
    "\n",
    "  def clean_arr(self):\n",
    "    cleaned_arr = []\n",
    "    if self.arr_similar == None:\n",
    "      raise Exception('Please fist call the function \\'get_closer_word\\'')\n",
    "    for tup in self.arr_similar:\n",
    "      if self.clean_word(tup[0]) not in self.ally_team:\n",
    "        cleaned_arr.append(tup)\n",
    "    self.arr_similar = cleaned_arr\n",
    "    return self.arr_similar\n",
    "\n",
    "  def get_pos(self,word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0]\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    element = tag_dict.get(tag)\n",
    "    if(element == \"j\" or element==\"n\" or element==\"v\" or element==\"r\"):\n",
    "        return element\n",
    "    return 'n'\n",
    "\n",
    "  def clean_word(self, word):\n",
    "    word = re.sub('[^a-zA-z]', ' ', word)\n",
    "    wl = WordNetLemmatizer()\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    return wl.lemmatize(word, pos = self.get_pos(word)) if word not in set(all_stopwords) else None \n",
    "\n",
    "  def all_math_combination(self):\n",
    "\n",
    "    self.ally_comb = []\n",
    "    self.enemy_comb = []\n",
    "    temp_ally_comb = []\n",
    "    temp_enemy_comb = []\n",
    "\n",
    "    for i in range(1,len(self.ally_team)+1):\n",
    "      if i == self.max_comb:\n",
    "        break\n",
    "      temp_ally_comb.append(np.array(list(combinations(self.ally_team,i)),dtype='object'))\n",
    "    for i in range(1,len(self.enemy_team)+1):\n",
    "      if i == self.max_comb:\n",
    "        break\n",
    "      temp_enemy_comb.append(np.array(list(combinations(self.enemy_team,i)),dtype='object'))\n",
    "\n",
    "    for i in temp_ally_comb:\n",
    "      for j in i:\n",
    "        self.ally_comb.append(j)\n",
    "    for i in temp_enemy_comb:\n",
    "      for j in i:\n",
    "        self.enemy_comb.append(j)\n",
    "    return self.ally_comb, self.enemy_comb\n",
    "\n",
    "  def update_table(self, deleted_words):\n",
    "    updated = False\n",
    "    for d in deleted_words:\n",
    "      if(d == self.assa_word[0]):\n",
    "        print(\"It was assasin word. You loosed!!\")\n",
    "        return\n",
    "    self.red_words = np.setdiff1d(self.red_words, deleted_words)\n",
    "    self.blue_words = np.setdiff1d(self.blue_words, deleted_words)\n",
    "    self.czn_words = np.setdiff1d(self.czn_words, deleted_words)\n",
    "    self.choose_side(self.ally_label)\n",
    "\n",
    "\n",
    "  def best_combination(self):\n",
    "    self.choose_side(self.ally_label)\n",
    "    self.all_math_combination()\n",
    "    best_tuple = (\"\",1)\n",
    "    best_num = None\n",
    "    best_ally = None\n",
    "    self.index = 0\n",
    "    while True:\n",
    "      for ally in self.ally_comb:\n",
    "        for enemy in self.enemy_comb:\n",
    "          if(len(ally)!=len(enemy)):\n",
    "            continue\n",
    "          temp = self.get_closer_word(ally,enemy)\n",
    "          if(temp[0][1] <= best_tuple[1]):\n",
    "            if((wv.distance(temp[self.index][0],self.assa_word[0]) < 0.6) or \n",
    "              (temp[self.index][0] not in words.words()) or \n",
    "              (temp[self.index][0] in ally[0]) or (ally[0] in temp[self.index][0])):\n",
    "              continue\n",
    "            best_tuple = temp[self.index]\n",
    "            best_num = len(ally)\n",
    "            best_ally = ally\n",
    "      if best_num == None:\n",
    "        self.index +=1\n",
    "        continue\n",
    "      break\n",
    "    return best_tuple, best_num, best_ally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "id": "OvgP_D_DbUNj"
   },
   "outputs": [],
   "source": [
    "ai = SpyMasterAI(model = wv, red_words=['chair','table','bench'],\n",
    "                             blue_words = ['cat','dog','rabbit'], \n",
    "                             czn_words = ['apple','banana','pear'],\n",
    "                             assa_word = ['piano'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "id": "FLDQeTWKdm_l"
   },
   "outputs": [],
   "source": [
    "ai.ally_label = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7A_Cxf_y2Xbv",
    "outputId": "bb407ba4-021b-4f1b-8391-1eb9bc1171ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('teak', 0.35301801562309265), 2, array(['table', 'bench'], dtype=object))"
      ]
     },
     "execution_count": 591,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.best_combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "id": "deh8jiuCkpuW"
   },
   "outputs": [],
   "source": [
    "ai.update_table(['table','chair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkLN5JzLkwIY",
    "outputId": "091d11b4-c467-44c1-faff-063e39091e3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bench'], dtype='<U5')"
      ]
     },
     "execution_count": 593,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.ally_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WAd27lqk82g",
    "outputId": "82528066-220b-4587-9588-c2b8561781c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('backfield', 0.36768731474876404), 1, array(['bench'], dtype=object))"
      ]
     },
     "execution_count": 594,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.best_combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbM6vEvorNeR",
    "outputId": "52c4f12b-1afb-4a2a-cbca-e0ef28d12f69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('bunny', 0.39691951870918274), 1, array(['rabbit'], dtype=object))"
      ]
     },
     "execution_count": 586,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.ally_label = 'blue'\n",
    "ai.best_combination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "id": "5_uFn9nAumhs"
   },
   "outputs": [],
   "source": [
    "ai.update_table(['rabbit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDUMyfNEun5O",
    "outputId": "ce87de48-ad8e-4301-9ac3-6a1512c153dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat', 'dog'], dtype='<U6')"
      ]
     },
     "execution_count": 601,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.ally_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqxeQjW5u77o",
    "outputId": "701f85b7-2067-4e57-e598-c005ac8cd1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('pet', 0.4606892764568329), 1, array(['dog'], dtype=object))"
      ]
     },
     "execution_count": 602,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.best_combination()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpyMasterAI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
